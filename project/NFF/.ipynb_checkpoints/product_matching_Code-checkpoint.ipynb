{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Json data to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('computers_train_xlarge.json',lines = True)\n",
    "data.to_csv('train.csv',index = False)\n",
    "df = pd.read_csv('train.csv')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning : Removing Unwanted Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.columns[[2,5,8,9,12,13,14,15,16,17]],axis=1,inplace =True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category_left'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category_right'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id_left'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['id_left'] < 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.index[df['label'] == 0],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description_left'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling the Null values of Description Columns by Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.description_left.fillna(df.title_left, inplace = True)\n",
    "df['description_left']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description_left'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description_right'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.description_right.fillna(df.title_left, inplace = True)\n",
    "df['description_right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description_right'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing category left and category right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category_match'] = np.where(df['category_left'] == df['category_right'],1,0)\n",
    "df.head()\n",
    "\n",
    "#1-Match / 0-Unmatch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category_match'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.index[df['category_match'] == 0],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category_match'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf=df.copy()\n",
    "newdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Maching Numbers function to match the products Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching_numbers(description_right, description_left):\n",
    "\n",
    "    description_right = set(re.findall(r'[0-9]+', description_right))\n",
    "    description_left = set(re.findall(r'[0-9]+', description_left))    \n",
    "    union = description_right.union(description_left)\n",
    "    intersection = description_right.intersection(description_left)\n",
    "\n",
    "    if len(description_right)==0 and len(description_left) == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return (len(intersection)/ len(union))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Levenshtein Text similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import jellyfish as jf\n",
    "def engineer_features(df):\n",
    "    \n",
    "    df['description_left'] = df['description_left'].str.lower()\n",
    "    df['description_right'] = df['description_right'].str.lower()\n",
    "\n",
    "    df['levenshtein_distance'] = df.apply(\n",
    "    lambda x: jf.levenshtein_distance(x['description_right'], \n",
    "                                      x['description_left']), axis=1)\n",
    "\n",
    "    df['matching_numbers'] = df.apply(\n",
    "    lambda x: matching_numbers(x['description_right'], \n",
    "                               x['description_left']), axis=1)\n",
    "\n",
    "    df['matching_numbers_log'] = (df['matching_numbers']+1).apply(np.log)\n",
    "    \n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df.fillna(value=0, inplace=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Required Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = engineer_features(df)\n",
    "df = df[['description_left','description_right','levenshtein_distance','matching_numbers']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sort_values(by=['levenshtein_distance'], ascending=[False])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining the mean ,count and max values of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['match'] = np.where(((df['levenshtein_distance']<60) & (df['matching_numbers']>0.7)),1,0)\n",
    "df['match'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Validation set For Finding Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_json('computers_gs.json',lines = True)\n",
    "data1.to_csv('test.csv',index = False)\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop(df_test.columns[[2,5,8,9,12,13,14,15,16,17]],axis=1,inplace =True)\n",
    "df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['description_right'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.description_right.fillna(df_test.title_left, inplace = True)\n",
    "df_test['description_right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['description_right'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['description_left'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.description_left.fillna(df_test.title_left, inplace = True)\n",
    "df_test['description_left']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['description_left'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['category_match'] = np.where(df_test['category_left'] == df_test['category_right'],1,0)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['category_match'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop(df_test.index[df_test['category_match'] == 0],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['category_match'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf_test=df_test.copy()\n",
    "newdf_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = engineer_features(df_test)\n",
    "df_test = df_test[['description_left','description_right','levenshtein_distance','matching_numbers','label']]\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['match'] = np.where(((df_test['levenshtein_distance']<40) & (df_test['matching_numbers']>0.4)),1,0)\n",
    "df_test['match'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df[['levenshtein_distance','matching_numbers']]\n",
    "X_test=df_test[['levenshtein_distance','matching_numbers']]\n",
    "y_train=df['match']\n",
    "y_test=df_test['match']\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Function For Finding Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix_values(y_test, y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    return(cm[0][0], cm[0][1], cm[1][0], cm[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building: Decision Tree,Random Forest and Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifiers = {\n",
    "    \"DecisionTreeClassifier\":DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=1, min_samples_split=4,random_state=42),\n",
    "    \"Support Vector Classifier\":SVC(kernel='rbf', gamma=0.1),\n",
    "    \"RandomForestClassifier\":RandomForestClassifier(n_estimators=1000,max_depth=4,random_state=42,n_jobs=-1),\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "df_results = pd.DataFrame(columns=['model', 'accuracy', 'precision',\n",
    "                                   'true_pos','false_pos',\n",
    "                                   'true_neg','false_neg','recall','f1'])\n",
    "\n",
    "for key in classifiers:\n",
    "\n",
    "    classifier = classifiers[key]\n",
    "    model = classifier.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    classification = classification_report(y_test, y_pred, zero_division=0)\n",
    "    tp, fp, fn, tn = get_confusion_matrix_values(y_test, y_pred)\n",
    "\n",
    "    row = {'model': key,\n",
    "           'accuracy': accuracy,\n",
    "           'precision': precision,\n",
    "              'Recall': recall,\n",
    "           'f1': f1,\n",
    "           'true_pos': tp,\n",
    "           'false_pos': fp,\n",
    "           'true_neg': tn,\n",
    "           'false_neg': fn,\n",
    "          }\n",
    "    df_results = df_results.append(row, ignore_index=True)\n",
    "\n",
    "df_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating Results in Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(data={'predictions': y_pred, 'actual': y_test})\n",
    "results['result'] = np.where(results['predictions']==results['actual'], 1, 0)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Results with Match and Not Matched Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['predictions'].replace(0, 'Not match',inplace=True)\n",
    "results['predictions'].replace(1, 'Match',inplace=True)\n",
    "\n",
    "results['actual'].replace(0, 'Not Match',inplace=True)\n",
    "results['actual'].replace(1, 'Match',inplace=True)\n",
    "\n",
    "results['result'].replace(0, 'False',inplace=True)\n",
    "results['result'].replace(1, 'True',inplace=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
